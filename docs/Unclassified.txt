------------------------------

其他相似项目

http://dlib.net/bayes.html

http://www.bnlearn.com/documentation/topics.html

https://www.bayesserver.com

https://github.com/eBay/bayesian-belief-networks
它在graph.py里也用到了topological sort。

Samlam (UCLA) (closed-source)

http://www.cs.cmu.edu/~javabayes/

------------------------------

为什么要有train_set_y_X

在Trainer.h中，有3个数组：train_set_y、train_set_X、train_set_y_X。

为什么要有train_set_y_X？

因为在计算mutual information的时候用它会方便很多，在生成Chow-Liu tree的时候，label node和feature node其实是平等的，只是我们要做classification的任务所以人为地把某个node选为了root（即label node）。

------------------------------

优化variable elimination过程

Zhang, N.L. & Poole, D. A simple approach to Bayesian network computations.
	* According to Theorem 1 and Corollary 1, we can remove a batch of nodes starting from each barren node.
	* According to Theorem 2, we can remove the nodes that are m-separated from X by Y.


So, how can we apply the above two theorems to the ***tree shape*** Bayesian network?
	1. The topological sorted order is generated by width-first traversal starting at the root node.
	2. Check the reversed topoligical sorted order sequentially, which enables us to check from the leaf nodes. 
	3. If a node being checked (it must be a leaf because of point 2) is not in $X \cup Y$, then remove it (using Theorem 1). This step can let us remove all the barren nodes.
	4. Now, the remaining network is a tree that every leaf is observed, which is in Y.
	5. Now we do a depth-first traversal starting at the root node, and do something to make the elimination order containing less nodes. (using Theorem 2)
	6. In a single run, we keep going down until we meet a node that is observed, which is in Y.
	7. Remove ***ALL*** the descendant of that node, then end this run, return to the root and start the next run.
	8. The remaining network now has the simplest structure, and the elimination order is optimal now.

------------------------------


------------------------------


------------------------------
